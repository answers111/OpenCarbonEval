
<h1 align="center">
<img src="./imgs/logo.png" width="100" alt="OpenCarbonEval" />
<br>
OpenCarbonEval: A Unified Carbon Emission Estimating Framework
</h1>

<div align="center">

![Static Badge](https://img.shields.io/badge/Carbon_footprint-Large_scale_models-blue)

</div>

<p align="center">
  <a href="https://github.com/answers111/OpenCarbonEval"><b>[üìú Paper]</b></a> ‚Ä¢
  <a href="https://github.com/answers111/OpenCarbonEval"><b>[üê± GitHub]</b></a> 
</p>

## üî• News

- [2024/05/22] OpenCarbonEval paper, repo, and website released.

<p align="center">
    <img src="./imgs/overview.png" width="800">
    <br>
    <em>Figure 1: The overview pipeline of OpenCarbonEval.</em>
</p>


## üí° Introduction

OpenCarbonEval is a unified framework for integrating large-scale models across diverse modalities to predict carbon emissions.

| Model         | Carbon Emission (tCO2eq)  |
|-----------------|--------------------|
| Gemini Ultra    | 18874.836015000023 |
| GPT-4           | 10072.847094100656 |
| MegaScale (Production) | 6994.666510237137 |
| Falcon-180B     | 3023.293196235459 |
| Inflection-2    | 3008.2428528510754 |
| Inflection-2.5  | 3005.5483355958013 |
| PaLM 2          | 2652.2807031301786 |
| Llama 3-70B     | 1896.6119244990025 |
| GPT-3.5 (text-davinci-003) | 1264.9537131658371 |
| Minerva (540B)  | 1001.1193324255153 |
| PaLM (540B)     | 984.6471571237539  |
| U-PaLM (540B)   | 924.6836594077137  |
| Flan-PaLM 540B  | 913.8363395822041  |
| GPT-3 175B (davinci)    | 562.6979538619452  |
| Megatron-Turing NLG 530B | 444.93751954629334 |
| xTrimoPGLM -100B| 425.0051199657541  |
| Llama 2-70B     | 308.9935544611769  |
| LaMDA           | 265.93353101873606 |
| Gopher (280B)   | 243.4786430801461  |
| BLOOM-176B      | 235.31716995889664 |
| LLaMA-65B       | 232.19416130961622 |
| PanGu-Œ£         | 221.31916800000005 |
| Falcon-40B      | 168.02645350050622 |
| OPT-175B        | 164.91871091971564 |
| Parti           | 157.5439264066853  |
| ViT-22B         | 149.15992320725013 |
| Galactica       | 124.56478062017767 |
| BloombergGPT    | 100.42817525297602 |
| ESM2-15B        | 89.06245490550333  |
| AlexaTM 20B     | 87.08825440739308  |
| Meena           | 86.6494523687247   |
| Nemotron-3-8B   | 76.79415273426348  |
| Pangu-Weather   | 70.17276729725828  |
| Skywork-13B     | 69.90592000000007  |
| iGPT-XL         | 66.76372369083475  |
| Switch          | 64.1592331579687   |
| ByT5-XXL        | 63.2493136166715   |
| ProtT5-XXL      | 59.96310052385477  |
| Flamingo        | 52.907172978979126 |
| WizardLM-7B     | 49.875415542724326 |
| FLAN 137B       | 41.35298259186699  |
| BlenderBot 3    | 39.990404023280576 |
| Meta Pseudo Labels | 37.976533324351664 |
| StarCoder       | 35.07479584655933  |
| CoAtNet         | 33.96785070295943  |
| Turing-NLG      | 33.17130901685255  |
| Llama 2-7B      | 32.67139021142524  |
| ProtBERT-BFD    | 32.324069971580116 |
| GOAT            | 31.902670660871728 |
| Taiyi-Stable Diffusion | 31.282032908762872 |
| ProtT5-XXL-BFD       | 30.713965686274793 |
| CoCa                 |  27.739332727451426 |
| T5-11B               |  26.451388071999176 |
| AlphaStar            |  24.427003583723693 |
| ALIGN                |  22.36287827485326 |
| Stable Diffusion (LDM-KL-8-G) |  21.5935672885323 |
| XGLM-7.5B            |  18.8012028058833 |
| LLaMA-7B               | 17.397606661982717 |
| BASIC-L              | 15.75653882933146 |
| T0-XXL               | 15.593792425177732 |
| CLIP (ViT L/14@336px) |  13.76222657972655 |
| Flan-T5 11B          |  12.652172748898744 |
| ProGen2-xlarge       |  11.115020815986023 |
| GShard (dense)       |  10.55579230785483 |
| NLLB                 |  6.904478087005021 |
| Imagen               |  5.649685613347577 |
| OmegaPLM             |  5.453333457079352 |

